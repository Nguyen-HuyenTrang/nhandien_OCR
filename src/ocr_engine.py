"""
Module OCR Engine - Nh·∫≠n d·∫°ng text t·ª´ h√¨nh ·∫£nh
"""
import pytesseract
from PIL import Image
import cv2
import numpy as np
import logging
import os
import sys
from pathlib import Path

# Th√™m th∆∞ m·ª•c config v√†o path
sys.path.append(str(Path(__file__).parent.parent))
from config.config import TESSERACT_CMD, OCR_LANG, MIN_CONFIDENCE

# C·∫•u h√¨nh Tesseract
if os.path.exists(TESSERACT_CMD):
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OCREngine:
    """Engine x·ª≠ l√Ω OCR ƒë·ªÉ nh·∫≠n d·∫°ng text t·ª´ ·∫£nh"""

    def __init__(self, lang: str = OCR_LANG):
        """
        Kh·ªüi t·∫°o OCR Engine

        Args:
            lang: Ng√¥n ng·ªØ nh·∫≠n d·∫°ng (m·∫∑c ƒë·ªãnh: vie+eng)
        """
        self.lang = lang
        self.logger = logger
        self.min_confidence = MIN_CONFIDENCE

        # Ki·ªÉm tra Tesseract
        self._check_tesseract()

    def _check_tesseract(self):
        """Ki·ªÉm tra Tesseract ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ch∆∞a"""
        try:
            version = pytesseract.get_tesseract_version()
            self.logger.info(f"‚úÖ Tesseract version: {version}")

            # Ki·ªÉm tra ng√¥n ng·ªØ c√≥ s·∫µn
            try:
                langs = pytesseract.get_languages()
                if 'vie' in langs:
                    self.logger.info("‚úÖ Vietnamese language pack available")
                else:
                    self.logger.warning("‚ö†Ô∏è Vietnamese language pack not found. OCR accuracy may be reduced.")
            except:
                pass

        except Exception as e:
            self.logger.error(f"‚ùå L·ªói: Tesseract ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t ho·∫∑c c·∫•u h√¨nh sai. {e}")
            self.logger.info("üìã H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t Tesseract:")
            self.logger.info("   Windows: https://github.com/UB-Mannheim/tesseract/wiki")
            self.logger.info("   Linux: sudo apt-get install tesseract-ocr tesseract-ocr-vie")
            raise RuntimeError("Tesseract OCR not properly configured")

    def extract_text(self, image_path, config: str = '--psm 6') -> str:
        """
        Tr√≠ch xu·∫•t text t·ª´ ·∫£nh

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ho·∫∑c numpy array
            config: C·∫•u h√¨nh Tesseract (PSM - Page Segmentation Mode)
                   --psm 3: Fully automatic (default)
                   --psm 6: Assume a single uniform block of text
                   --psm 11: Sparse text

        Returns:
            str: Text ƒë∆∞·ª£c nh·∫≠n d·∫°ng
        """
        try:
            # ƒê·ªçc ·∫£nh n·∫øu l√† ƒë∆∞·ªùng d·∫´n, ho·∫∑c d√πng tr·ª±c ti·∫øp n·∫øu l√† numpy array
            if isinstance(image_path, str):
                image = Image.open(image_path)
            else:
                # Convert numpy array to PIL Image
                import cv2
                if len(image_path.shape) == 3:
                    image = Image.fromarray(cv2.cvtColor(image_path, cv2.COLOR_BGR2RGB))
                else:
                    image = Image.fromarray(image_path)

            # OCR v·ªõi config
            text = pytesseract.image_to_string(
                image,
                lang=self.lang,
                config=config
            )

            self.logger.info(f"Tr√≠ch xu·∫•t text th√†nh c√¥ng t·ª´: {image_path}")
            return text.strip()

        except Exception as e:
            self.logger.error(f"L·ªói khi tr√≠ch xu·∫•t text: {e}")
            return ""

    def extract_text_with_confidence(self, image_path) -> dict:
        """
        Tr√≠ch xu·∫•t text k√®m ƒë·ªô tin c·∫≠y

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ho·∫∑c numpy array

        Returns:
            dict: {
                'text': str,
                'confidence': float,
                'details': list of dict
            }
        """
        try:
            # ƒê·ªçc ·∫£nh n·∫øu l√† ƒë∆∞·ªùng d·∫´n, ho·∫∑c d√πng tr·ª±c ti·∫øp n·∫øu l√† numpy array
            if isinstance(image_path, str):
                image = Image.open(image_path)
            else:
                # Convert numpy array to PIL Image
                import cv2
                if len(image_path.shape) == 3:
                    image = Image.fromarray(cv2.cvtColor(image_path, cv2.COLOR_BGR2RGB))
                else:
                    image = Image.fromarray(image_path)

            # L·∫•y d·ªØ li·ªáu chi ti·∫øt
            data = pytesseract.image_to_data(
                image,
                lang=self.lang,
                output_type=pytesseract.Output.DICT
            )

            # L·ªçc c√°c t·ª´ c√≥ ƒë·ªô tin c·∫≠y ƒë·ªß
            filtered_text = []
            confidences = []
            details = []

            n_boxes = len(data['text'])
            for i in range(n_boxes):
                confidence = int(data['conf'][i])
                text = data['text'][i].strip()

                if confidence > 0 and text:
                    if confidence >= self.min_confidence:
                        filtered_text.append(text)
                        confidences.append(confidence)

                    details.append({
                        'text': text,
                        'confidence': confidence,
                        'left': data['left'][i],
                        'top': data['top'][i],
                        'width': data['width'][i],
                        'height': data['height'][i]
                    })

            avg_confidence = sum(confidences) / len(confidences) if confidences else 0

            result = {
                'text': ' '.join(filtered_text),
                'confidence': round(avg_confidence, 2),
                'details': details
            }

            self.logger.info(f"ƒê·ªô tin c·∫≠y trung b√¨nh: {avg_confidence:.2f}%")
            return result

        except Exception as e:
            self.logger.error(f"L·ªói khi tr√≠ch xu·∫•t text v·ªõi confidence: {e}")
            return {'text': '', 'confidence': 0, 'details': []}

    def extract_structured_data(self, image_path: str) -> dict:
        """
        Tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c t·ª´ nh√£n b∆∞u ki·ªán

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ho·∫∑c text ƒë√£ OCR

        Returns:
            dict: Th√¥ng tin ƒë∆∞·ª£c tr√≠ch xu·∫•t
        """
        result = {
            'sender_name': '',
            'sender_address': '',
            'sender_phone': '',
            'recipient_name': '',
            'recipient_address': '',
            'recipient_phone': '',
            'postal_code': '',
            'weight': '',
            'order_id': '',
            'raw_text': '',
            'confidence': 0
        }

        try:
            # L·∫•y text v·ªõi confidence (ho·∫∑c d√πng text ƒë√£ c√≥)
            import os
            if isinstance(image_path, str) and os.path.isfile(image_path):
                # L√† ƒë∆∞·ªùng d·∫´n file ·∫£nh
                ocr_result = self.extract_text_with_confidence(image_path)
                text = ocr_result['text']
                result['confidence'] = ocr_result['confidence']
            else:
                # ƒê√£ l√† text ho·∫∑c kh√¥ng ph·∫£i file
                text = str(image_path)
                result['confidence'] = 0

            result['raw_text'] = text

            # S·ª≠ d·ª•ng PostalLabelParser ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin
            from src.postal_label_parser import PostalLabelParser
            parser = PostalLabelParser()
            parsed = parser.parse(text)

            # C·∫≠p nh·∫≠t result v·ªõi d·ªØ li·ªáu ƒë√£ parse
            result.update(parsed)

            self.logger.info("Tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c th√†nh c√¥ng")
            return result

        except Exception as e:
            self.logger.error(f"L·ªói khi tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return result

    def _split_sender_recipient(self, text: str) -> tuple:
        """T√°ch text th√†nh ph·∫ßn ng∆∞·ªùi g·ª≠i v√† ng∆∞·ªùi nh·∫≠n"""
        import re

        # T√¨m v·ªã tr√≠ c·ªßa "Ng∆∞·ªùi g·ª≠i" v√† "Ng∆∞·ªùi nh·∫≠n"
        sender_match = re.search(r'Ng[∆∞u]+[o∆°]+i\s+g[·ª≠·ªØ]+i', text, re.IGNORECASE)
        recipient_match = re.search(r'Ng[∆∞u]+[o∆°]+i\s+nh[·∫≠a]+n', text, re.IGNORECASE)

        if sender_match and recipient_match:
            sender_start = sender_match.start()
            recipient_start = recipient_match.start()

            if sender_start < recipient_start:
                sender_section = text[sender_start:recipient_start]
                recipient_section = text[recipient_start:]
            else:
                recipient_section = text[recipient_start:sender_start]
                sender_section = text[sender_start:]
        elif sender_match:
            sender_section = text[sender_match.start():]
            recipient_section = ''
        elif recipient_match:
            recipient_section = text[recipient_match.start():]
            sender_section = ''
        else:
            # Kh√¥ng t√¨m th·∫•y, th·ª≠ t√°ch theo v·ªã tr√≠
            mid = len(text) // 2
            sender_section = text[:mid]
            recipient_section = text[mid:]

        return sender_section, recipient_section

    def _extract_name(self, text: str, person_type: str) -> str:
        """Tr√≠ch xu·∫•t t√™n ng∆∞·ªùi t·ª´ text"""
        import re

        # Pattern: Ng∆∞·ªùi g·ª≠i/nh·∫≠n + T√äN (vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu) + s·ªë/ƒë·ªãa ch·ªâ
        # VD: "Ng∆∞·ªùi g·ª≠i LUX PERFUMEE" ho·∫∑c "Ng∆∞·ªùi nh·∫≠n B√πi Tu·∫•n V≈©"
        if person_type == 'sender':
            # T√¨m text sau "Ng∆∞·ªùi g·ª≠i" ƒë·∫øn tr∆∞·ªõc s·ªë ho·∫∑c ƒë·ªãa ch·ªâ
            pattern = r'Ng[∆∞u]+[o∆°]+i\s+g[·ª≠·ªØ]+i\s+([A-Z][A-Za-z√Ä-·ªπ\s]+?)(?=\s*\d|\s+[pqthƒë]|$)'
        else:
            # T√¨m text sau "Ng∆∞·ªùi nh·∫≠n" ƒë·∫øn tr∆∞·ªõc s·ªë ho·∫∑c ƒë·ªãa ch·ªâ
            pattern = r'Ng[∆∞u]+[o∆°]+i\s+nh[·∫≠a]+n\s+([A-Z][A-Za-z√Ä-·ªπ\s]+?)(?=\s*[A-Z]?\d|\s+[SsNn][·ªëo∆°]|$)'

        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            name = match.group(1).strip()
            # Lo·∫°i b·ªè s·ªë v√† k√Ω t·ª± l·∫° ·ªü cu·ªëi
            name = re.sub(r'\s+\d.*$', '', name)
            name = re.sub(r'\s{2,}', ' ', name)
            # Ch·ªâ l·∫•y t·ªëi ƒëa 5 t·ª´ (t√™n ng∆∞·ªùi th∆∞·ªùng kh√¥ng qu√° d√†i)
            words = name.split()
            if len(words) > 5:
                name = ' '.join(words[:5])
            return name.strip()

        return ''

    def _extract_address(self, text: str) -> str:
        """Tr√≠ch xu·∫•t ƒë·ªãa ch·ªâ t·ª´ text"""
        import re

        # T√¨m ƒë·ªãa ch·ªâ d·ª±a tr√™n keywords
        address_keywords = [
            r'(?:S·ªë\s+)?(\d+[A-Z]?\d*[,\s]+[^,\n]+?(?:ph∆∞·ªùng|ph∆∞[o∆°]+ng|qu·∫≠n|qu[a·∫≠]+n|huy·ªán|huy[e·ªá]+n|th√†nh ph·ªë|t·ªânh|th·ªã x√£)[^,\n]*(?:,\s*[^,\n]+)*)',
            r'(\d+\s+[^,\n]+?(?:ƒë∆∞·ªùng|[ƒëd]u[o∆°]+ng)[^,\n]*(?:,\s*[^,\n]+)*)',
            r'((?:ph∆∞·ªùng|qu·∫≠n|huy·ªán|th√†nh ph·ªë|t·ªânh)\s+[^,\n]+(?:,\s*[^,\n]+)*)'
        ]

        for pattern in address_keywords:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                # L·∫•y ƒë·ªãa ch·ªâ d√†i nh·∫•t (th∆∞·ªùng l√† ƒë·∫ßy ƒë·ªß nh·∫•t)
                address = max(matches, key=len)
                # L√†m s·∫°ch ƒë·ªãa ch·ªâ
                address = re.sub(r'\s+', ' ', address)
                address = address.strip()
                return address

        # Fallback: t√¨m d√≤ng c√≥ ch·ª©a ƒë·ªãa ch·ªâ
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if any(kw in line.lower() for kw in ['ph∆∞·ªùng', 'qu·∫≠n', 'huy·ªán', 't·ªânh', 'th√†nh ph·ªë']):
                # Lo·∫°i b·ªè s·ªë ƒëi·ªán tho·∫°i v√† m√£ n·∫øu c√≥
                cleaned = re.sub(r'\b0\d{9,10}\b', '', line)
                cleaned = re.sub(r'\b\d{5,6}\b', '', cleaned)
                cleaned = re.sub(r'\s+', ' ', cleaned).strip()
                if len(cleaned) > 20:  # ƒê·ªãa ch·ªâ ph·∫£i c√≥ ƒë·ªô d√†i nh·∫•t ƒë·ªãnh
                    return cleaned

        return ''

    def _is_phone_number(self, text: str) -> bool:
        """Ki·ªÉm tra xem text c√≥ ch·ª©a s·ªë ƒëi·ªán tho·∫°i kh√¥ng"""
        import re
        # T√¨m chu·ªói s·ªë li√™n ti·∫øp 10-11 ch·ªØ s·ªë b·∫Øt ƒë·∫ßu b·∫±ng 0
        pattern = r'0\d{9,10}'
        return bool(re.search(pattern, text))

    def _extract_phone_number(self, text: str) -> str:
        """Tr√≠ch xu·∫•t s·ªë ƒëi·ªán tho·∫°i t·ª´ text"""
        import re

        # Pattern cho s·ªë ƒëi·ªán tho·∫°i Vi·ªát Nam
        patterns = [
            r'0\d{9,10}',  # 10-11 s·ªë b·∫Øt ƒë·∫ßu b·∫±ng 0
            r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}',  # Format c√≥ d·∫•u ph√¢n c√°ch
        ]

        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                phone = match.group()
                # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
                return ''.join(c for c in phone if c.isdigit())

        return ''

    def _extract_postal_code(self, text: str) -> str:
        """Tr√≠ch xu·∫•t m√£ b∆∞u ch√≠nh"""
        import re

        # M√£ b∆∞u ch√≠nh Vi·ªát Nam: 5-6 s·ªë
        pattern = r'\b\d{5,6}\b'
        match = re.search(pattern, text)

        if match:
            return match.group()

        return ''

    def visualize_ocr_result(self, image_path: str, output_path: str) -> None:
        """
        V·∫Ω k·∫øt qu·∫£ OCR l√™n ·∫£nh

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh g·ªëc
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh k·∫øt qu·∫£
        """
        try:
            # ƒê·ªçc ·∫£nh
            image = cv2.imread(image_path)

            # L·∫•y d·ªØ li·ªáu OCR
            pil_image = Image.open(image_path)
            data = pytesseract.image_to_data(
                pil_image,
                lang=self.lang,
                output_type=pytesseract.Output.DICT
            )

            # V·∫Ω bounding boxes
            n_boxes = len(data['text'])
            for i in range(n_boxes):
                confidence = int(data['conf'][i])
                text = data['text'][i].strip()

                if confidence > self.min_confidence and text:
                    x, y, w, h = (data['left'][i], data['top'][i],
                                 data['width'][i], data['height'][i])

                    # V·∫Ω rectangle
                    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

                    # Ghi text v√† confidence
                    label = f"{text} ({confidence}%)"
                    cv2.putText(image, label, (x, y - 10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

            # L∆∞u ·∫£nh
            cv2.imwrite(output_path, image)
            self.logger.info(f"ƒê√£ l∆∞u ·∫£nh visualization t·∫°i: {output_path}")

        except Exception as e:
            self.logger.error(f"L·ªói khi visualization: {e}")


if __name__ == "__main__":
    # Test
    ocr = OCREngine()
    print("OCREngine module loaded successfully!")
